max_seq_len: None #Max number of words to consider per example when xbert/preprocessing.
#Default is 128. MIMIC mean/std/max = 1358/792/7711
max_char_len: None # Max number of characters to consider per example when xbert/preprocessing.
#Default is 4096. MIMIC mean/std/max = 8794/5118/51230
local_attention_window: 512
global_attention_window: 4096 #Max number of tokens to consider. MIMIC mean/std/max = 2742/1602/17593
base_model_name: 'allenai/biomed_roberta_base'
model_name: 'simonlevine/biomed_roberta_base-4096'
prepare_for_xbert:
  subsampling: true
  icd_version: '9' #if 10, only diag codes currently implemented, so will error out.
  diag_or_proc: 'diag'
  one_or_all_icds: 'all' #load in 'all' ICDs, otherwise an int (i.e., 1 for just primary).
  note_category: 'Discharge summary' #load in all categories, otherwise a string (i.e., 'Discharge summary').
xbert_model_training:
  # max_steps: 1000
  # warmup_steps: 100
  # logging_steps: 50
  # learning_rate: 0.00005
  max_steps: 8
  warmup_steps: 2
  logging_steps: 4
  learning_rate: 0.05