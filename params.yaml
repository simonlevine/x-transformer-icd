max_seq_len: 2048
local_attention_window: 512
global_attention_window: 2048
base_model_name: 'allenai/biomed_roberta_base'
model_name: 'simonlevine/biomed_roberta_base-2048'
prepare_for_xbert:
  subsampling: true
  icd_version: 9
xbert_model_training:
  # max_steps: 1000
  # warmup_steps: 100
  # logging_steps: 50
  # learning_rate: 0.00005
  max_steps: 20
  warmup_steps: 2
  logging_steps: 10
  learning_rate: 0.05